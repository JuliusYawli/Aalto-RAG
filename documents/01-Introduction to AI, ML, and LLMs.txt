
--- Page 1 ---
Introduction to AI, ML, and 
LLMs
Dariush Salami
3rd Feb 2026
Introduction to AI, ML, and LLMs 1
--- Page 2 ---
Dariush Salami     Ø¯Ø§Ø±ÛŒÙˆØ´
â€¢PhD from Aalto University on AI and ML for 
wireless communication and sensing
â€¢ Postdoctoral researcher at Aalto University
â€¢ Radio research scientist at Nokia Bell Labs
â€¢ Over 10 years of experience in academia and 
industry
â€¢ Lectured the largest AIML course in Finland 
with over 1000 attendees
Introduction to AI, ML, and LLMs 2
--- Page 3 ---
Course schedule
01 Introduction to AI, ML, and LLMs
02 Basics of Machine Learning (Industrial talk)
03 Data Preprocessing for NLP
04 Introduction to LLMs and Their Applications
05 Supervised Learning for NLP Tasks
06 Advanced NLP Techniques
07 Language Generation with LLMs
08 Ethical Considerations and Challenges in LLMs
09 Model Deployment and Integration in Applications
10 Final Project and Presentation
â€¢ Course time: 9-12
â€¢ Grading: fail/pass
â€¢ 3 Credits
â€¢ Location: Maarintie 8 Room 
1174 TU4
Introduction to AI, ML, and LLMs 3
--- Page 4 ---
I3 Approach
â€¢ Immediate, real-time feedback and deeper engagement 
with the instructor and peers.
â€¢ Promotes networking, idea exchange, and collaboration 
beyond the session itself.
In-person:
â€¢ Encourages questions, exploration, and adaptive pacing 
based on participant needs.
â€¢ Promotes active learning through live coding, discussions, 
polls, and group activities.
Interactive:
â€¢ Bridges theory and practice with real-world use cases, 
tools, and datasets from industry.
â€¢ Exposes participants to challenges, solutions, and 
workflows used in production LLM systems.
Industrial:
Introduction to AI, ML, and LLMs 4
--- Page 5 ---
Interested in reading more?
Deep Learning
By Ian Goodfellow, Yoshua 
Bengio, Aaron Courville
Artificial Intelligence: A 
Modern Approach
By Stuart Russell, Peter Norvig
Pattern Recognition and 
Machine Learning
By Christopher M. Bishop
Introduction to AI, ML, and LLMs 5
--- Page 6 ---
Final project 
or 
presentation
The last session of the course is dedicated to 
presentations and potential feedback on the projects.
Presentations:
â€¢ Four presentations in total (20 minutes + 10 minutes QA).
â€¢ Each group two people maximum.
â€¢ Free to choose the topic as long as itâ€™s aligned with the course 
content.
â€¢ Deadline is the last day of the course.
Projects:
â€¢ Three to five people per group
â€¢ Four candidate topics
â€¢ Deadline is one week after the course finishes.
Introduction to AI, ML, and LLMs 6
--- Page 7 ---
Why this winter school?
â€¢ To learn the basic concepts in AI/ML and LLMs.
â€¢ To have a theoretical-practical understanding of the LLMs.
â€¢ To get exposed to different technologies in LLMs so that you can 
dive deeper after the summer school if you find something more 
interesting.
â€¢ To get start writing simple AI/ML applications using 
NoCode/LowCode approaches plus using more advanced 
libraries like LangChain! 
Introduction to AI, ML, and LLMs 7
--- Page 8 ---
Lecture day plan
â€¢ 9:00â€“9:10
â€¢ Arrival buffer / settling in
â€¢ 9:10â€“9:30
â€¢ Q.A. and project/presentation check up
â€¢ 9:30â€“10:30
â€¢ First lecture
â€¢ 10:30â€“10:45
â€¢ Break
â€¢ 10:45â€“11:45
â€¢ Second lecture
â€¢ 11:45â€“12:00
â€¢ Final Q&A & wrap-up
Introduction to AI, ML, and LLMs 8
--- Page 9 ---
Candidate 
project topics 
(No-Code, 
Low-Code)
â€¢ AI Content Assistant with n8n
â€¢ Design a workflow using n8n that 
automatically generates social media posts 
from survey responses or meeting notes.
â€¢ Coding Required: None (low-code 
configuration).
â€¢ A working n8n workflow (hosted or in a local 
setup).
â€¢ A reflection slide on how LLMs can help 
automate routine writing tasks.
â€¢ AI Travel Planner App with Flowise
â€¢ Design and build a Flowise app that acts as a 
travel assistant helping users plan a trip to a 
city, region, or country of your choice using an 
LLM + modular logic.
â€¢ Coding Required: Flowise config + light prompt 
design.
â€¢ A working Flowise app (hosted or demoed live / 
video walkthrough).
â€¢ A reflection slide on app purpose and features 
as well as the Flowise architecture.
Introduction to AI, ML, and LLMs 9
--- Page 10 ---
Candidate 
project topics 
(Intermediate, 
Advanced)
â€¢ AI Policy Advisor: Multi-Agent LLM System for 
Drafting Ethical AI Guidelines
â€¢ Develop a multi-agent system (using LangChain, 
CrewAI, or LangGraph) where AI â€œexpertsâ€ 
collaborate to draft a simple, high-level policy 
document on responsible AI use in a domain (e.g., 
education, healthcare, smart cities).
â€¢ Coding Required: Intermediate (Python + 
LangChain/CrewAI basics + agent configuration).
â€¢ A runnable Python script or Colab notebook.
â€¢ A short draft (e.g., â€œ5 principles for safe AI in smart 
citiesâ€) produced collaboratively by the agents.
â€¢ RAG Application for Domain-Specific Question 
Answering
â€¢ Create a Retrieval-Augmented Generation (RAG) 
system that answers user questions based on 
custom documents (e.g., company manuals, 
scientific papers, product specs).
â€¢ Coding Required: Medium to high (Python, 
LangChain, basic vector database setup)
â€¢ A working RAG app (Python script or Colab 
notebook).
Introduction to AI, ML, and LLMs 10
--- Page 11 ---
Course schedule
01 Introduction to AI, ML, and LLMs
02 Basics of Machine Learning
03 Data Preprocessing for NLP
04 Introduction to LLMs and Their Applications (Industrial talk)
05 Supervised Learning for NLP Tasks
06 Advanced NLP Techniques
07 Language Generation with LLMs
08 Ethical Considerations and Challenges in LLMs
09 Model Deployment and Integration in Applications
10 Final Project and Presentation
Introduction to AI, ML, and LLMs 11
--- Page 12 ---
What are Artificial 
Intelligence and 
Machine Learning?
Introduction to AI, ML, and LLMs 12
--- Page 13 ---
Introduction to AI, ML, and LLMs 13

--- Page 14 ---
Introduction to AI, ML, and LLMs 14
--- Page 15 ---
A Brief History of 
AI
â€¢ The idea of intelligent machines appears in 
ancient myths and early automata (e.g., 
mechanical statues, clockwork devices).
â€¢ 1940sâ€“50s: Foundations laid with work on 
cybernetics, formal logic, and early computers.
â€¢ 1956: The term Artificial Intelligence was 
coined at the Dartmouth Conference, organized 
by John McCarthy.
â€¢ The Dartmouth Conference is considered the 
official birth of AI as a field of study.
â€¢ Early AI programs (1950sâ€“60s) tackled tasks like 
playing chess, solving algebra, and proving 
theorems.
â€¢ Periods of rapid progress alternated with AI 
winters â€” times of reduced funding and 
interest.
Introduction to AI, ML, and LLMs 15
--- Page 16 ---
Introduction to AI, ML, and LLMs 16

--- Page 17 ---
Human can learn from past experience and 
make decision of its own.
Introduction to AI, ML, and LLMs 17
What is this object?
Itâ€™s a car!
--- Page 18 ---
Let us ask the same question to a 
neanderthalâ€¦
Introduction to AI, ML, and LLMs 18
What is this object?
However, he is a human being.
He can observe and learn if we
show him pictures of cars!
--- Page 19 ---
Let us teach him by showing pictures of 
different cars
Introduction to AI, ML, and LLMs 19

--- Page 20 ---
Let us ask the same question now
Introduction to AI, ML, and LLMs 20
What is this object?
Itâ€™s a car!
--- Page 21 ---
AI, ML, NN, and DL!
Introduction to AI, ML, and LLMs 21
https://www.qlik.com/us/augmented-analytics/machine-learning-vs-ai
--- Page 22 ---
What about a Machine ?
Introduction to AI, ML, and LLMs 22
Machines follow instructions
[ It can not take decision of its own]
--- Page 23 ---
What about a Machine ?
Introduction to AI, ML, and LLMs 23
We can ask a machine
â€¢ To perform an arithmetic operations such as
â€¢ Addition
â€¢ Multiplication
â€¢ Division
â€¢ Comparison
â€¢ Print
â€¢ Plot a chart
--- Page 24 ---
What is Machine Learning?
Introduction to AI, ML, and LLMs 24
We want a machine to act like a human.
Detect 
objects
Predict 
values 
Learn our 
language
Recognize 
faces
Pretty much the learning process is the 
same! We need to provide experience to 
the machine!
--- Page 25 ---
What is Machine Learning?
Introduction to AI, ML, and LLMs 25
Data or Training Dataset
+
So, we first need to provide
training dataset to the
machine.
--- Page 26 ---
What is Machine Learning?
Introduction to AI, ML, and LLMs 26
Dataset
+ +
Then, develop algorithms and 
execute programs on the data 
w.r.t the desired tasks.
--- Page 27 ---
What is Machine Learning?
Introduction to AI, ML, and LLMs 27
Dataset
+ +
 +
Identify required rules
--- Page 28 ---
What is Machine Learning?
Introduction to AI, ML, and LLMs 28
Dataset
+ +
 +
Extract required patterns

--- Page 29 ---
What is Machine Learning?
Introduction to AI, ML, and LLMs 29
Dataset
+ +
 +
Extract required patterns

--- Page 30 ---
In summary, what is machine learning?
Introduction to AI, ML, and LLMs 30
+ +
 +
 + Decision
Given a machine learning problem
â€¢ Identify and create the appropriate dataset
â€¢ Perform computation to learn
â€¢ Required rules, pattern and relations
â€¢ Output the decision
--- Page 31 ---

--- Page 32 ---
Introduction to AI, ML, and LLMs 32

--- Page 33 ---
What are Large 
Language Models 
(LLMs)?
Introduction to AI, ML, and LLMs 33
--- Page 34 ---
Introduction to AI, ML, and LLMs 34

--- Page 35 ---
Turing predicted by 2000 a 
machine would be able to fool 
an average person to believe 
that itâ€™s a real human!
Try it yourself: https://turingtest.live/
A human evaluator interacts (via 
text) with both a machine and a 
human.
The evaluatorâ€™s task: decide which is 
the machine and which is the 
human.
A machine passes the test if the 
evaluator cannot reliably tell them 
apart.
Focuses on behavior, not inner 
workings, can the machine imitate 
human responses convincingly?
Introduction to AI, ML, and LLMs 35
--- Page 36 ---
Rank these 
sentences in 
the order of 
plausibility?
1. Dog ball the chased the.
2. The chased dog the ball.
3. The dog chase the ball.
4. The dog chased the ball.
5. The ball chased the dog.
6. The dog chased a sky.
Introduction to AI, ML, and LLMs 36
--- Page 37 ---
Introduction to AI, ML, and LLMs 37
--- Page 38 ---
The language modeling problem
p(how are you this evening ? has your house ever been burgled?) = 10-15
p(how are you this evening ? fine , thanks , how about you?) = 10-9
Introduction to AI, ML, and LLMs 38

--- Page 39 ---
Complete this 
sentence: Finland is 
_______.
Introduction to AI, ML, and LLMs 39
--- Page 40 ---
Introduction to AI, ML, and LLMs 40

--- Page 41 ---
The language modeling problem
Introduction to AI, ML, and LLMs 41
Finland is _________. 
beautiful
warm
cold
duck
[the rest of the vocabulary.]

--- Page 42 ---
At each timestep, sample a token from the language modelâ€™s new probability 
distribution over next tokens. In short, predicting which word comes next.
Language models of this form can generate 
text
Introduction to AI, ML, and LLMs 42
Finland is a _________. 
beautiful
warm
cold
duck
[the rest of the vocabulary.]
Finland _________. 
Finland is _________. 
--- Page 43 ---
Language models are
â€¢ â€She loves itâ€ or
â€¢ â€She love itâ€a grammatical judge
â€¢ â€The boy crossed the streetâ€ or
â€¢ â€The TV crossed the streetâ€
a semantic plausibility 
judge
â€¢ â€A: How are you? B: Thanks, Iâ€™m ok, how about you?â€ or
â€¢ â€œA: How are you? B: Have you ever been to France?â€a consistency judge
â€¢ â€Tehran is the capital of Iran. â€a knowledge repository 
(Very difficult to guarantee!)
Introduction to AI, ML, and LLMs 43
--- Page 44 ---
We use language models in daily basis!
Introduction to AI, ML, and LLMs 44

--- Page 45 ---
How do we learn 
a language 
model?
â€¢ Estimate probabilities using text data
â€¢ Collect a textual corpus
â€¢ Find a distribution that maximizes the probability of the corpus 
(maximum likelihood estimation).
â€¢ A naive solution: count and divide
â€¢ Assume we have N training sentences
â€¢ Let x1, x2, ..., xn be a sentence, and c(x1, x2, ..., xn) be the number 
of times it appeared in the training data.
â€¢ Define a language model:
Introduction to AI, ML, and LLMs 45
--- Page 46 ---
Markov assumption
â€¢ We make the Markov assumption: x(t+1) depends only on the 
preceding n-1 words
ğ‘ƒ ğ‘¥ ğ‘¡+1 |ğ‘¥ ğ‘¡ , â€¦ , ğ‘¥ 1 = ğ‘ƒ ğ‘¥ ğ‘¡+1 |ğ‘¥ ğ‘¡ , â€¦ , ğ‘¥ ğ‘¡âˆ’ğ‘›+2
Introduction to AI, ML, and LLMs 46
n-1 words

--- Page 47 ---
n-gram Language Models
Introduction to AI, ML, and LLMs 47
à·‘
ğ‘–=1
ğ‘
ğ‘ƒ ğ‘¥ ğ‘¡+1 |ğ‘¥ ğ‘¡ , â€¦ , ğ‘¥ ğ‘–âˆ’1
â€¢ Definition: An n-gram model predicts the next word based on the 
previous (n-1) words.
â€¢ Example sentence: "I have a dog whose name is Lucy. I have two 
cats, they like playing with Lucy. "
â€¢ Key concept: Collect statistics on n-gram frequencies to predict 
the next word
â€¢ Process:
â€¢ Step 1: Identify sequences of n words (n-grams) in the text
â€¢ Step 2: Calculate the probability of each n-gram
â€¢ Step 3: Use probabilities to predict the next word
--- Page 48 ---
Unigram probability
Introduction to AI, ML, and LLMs 48
â€¢ â€œI have a dog whose name is Lucy. I have two cats, they like 
playing with Lucy. â€
â€¢ corpus size m = 17
â€¢ P(Lucy) = 2/17; P(cats) = 1/17
â€¢ Unigram probability:

--- Page 49 ---
Bigram probability
Introduction to AI, ML, and LLMs 49
â€¢ â€œI have a dog whose name is Lucy. I have two cats, they like 
playing with Lucy.â€

--- Page 50 ---
n-gram probability
Introduction to AI, ML, and LLMs 50
â€¢ â€œI have a dog whose name is Lucy. I have two cats, they like 
playing with Lucy. â€

--- Page 51 ---
Neural language models
Introduction to AI, ML, and LLMs 51
à·‘
ğ‘–=1
ğ‘
ğ‘ƒ ğ‘¥ ğ‘¡+1 |ğ‘¥ ğ‘¡ , â€¦ , ğ‘¥ ğ‘–âˆ’1
I have a dog whose name is 
Lucy. I have two ğ‘“(ğœƒ)
A differentiable 
function (e.g. a 
neural 
network)
A distribution over
the vocabulary

--- Page 52 ---
Quiz time: 
what is my 
name in 
Persian?
Ø¯Ø±ÙˆÛŒØ´
Ø¯Ø§Ø±ÛŒÙˆØ´
Ù†Ù…ÛŒØ¯Ø§Ù†Ù…
Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù…
Introduction to AI, ML, and LLMs 52
--- Page 53 ---
Introduction to AI, ML, and LLMs 53

--- Page 54 ---
Questions?
dariush.salami@aalto.fi
Introduction to AI, ML, and LLMs
54